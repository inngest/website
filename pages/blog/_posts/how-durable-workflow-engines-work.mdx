---
heading: "How a durable workflow engine works"
subtitle: Providing a way to handle high load events, and processing them in bulk
image: /assets/blog/event-batching/main.png
date: 2023-09-25
disableCTA: true
---

## Content overview

- What are durable workflow engines
- Why are workflow engines good?
- How they work, high level
- Nuances and approaches in the landscape

## What are durable workflow engines?

Durable workflow engines are a powerful emerging technology which allow developers to write
reliable code without worrying about queues or state management.  A good workflow engine is code
first, and should get out of your way and let you think about your code.  We're not talking about
[BPMN](https://en.wikipedia.org/wiki/Business_Process_Model_and_Notation), here.

Without workflow engines, it's common to write code to run as a task within a queue,
push jobs to that queue, and chain jobs together to build what you need.  Using a workflow engine is
much simpler:  you write code as a series of steps, each of which is enqueued and attempted until
successful. Here's an example of a billing function written as a workflow using Inngest:

```typescript
import { lib } from "src/lib";
import { inngest } from "src/inngest/client"

inngest.createFunction(
  { id: "handle-payments", name: "Handle payments" }, // Basic function name and configuration
  { event: "api/invoice.created" },                   // Run any time a new invoice is created.
  async ({ event, step }) => {
    // Wait until the next billing date.
    await step.sleepUntil(event.data.invoiceDate);

    for (let i = 0; i < 3; i++) {
      const charge = await step.run("Attempt charge", async () => {
        // Note: This throws an error and retries automatically if the charge
        // cannot be attempted.  If a charge is attempted, the returning
        // object will specify whether the charge is successful.
        return await lib.stripe.charges.create({
          user: event.data.accountId,
          amount: event.data.amount,
        });
      });

      if (charge.success) {
        // Run two steps in parallel, both enqueued for reliability.
        await Promise.all([
          step.run("Update DB", async () => {
            await db.payments.upsert(charge)
          }),
          step.run("Send receipt", async () => {
            await resend.emails.send({
              to: event.user.email,
              subject: "Your receipt for Inngest",
            })
          })
        ]);
        // Done.  Return the charge for observability.
        return charge;
      }

      // Wait 24 hours and retry.
      await step.sleep("24h");
    }

    // If we're here, we've retried 3 times and we haven't been able to
    // succeed with a payment. Handle the failure.
    await step.run("Handle permanently failed payment", async () => {
      lib.accounts.suspend(event.data.accountId);
    });
  },
);
```

This function uses workflow primitives to create reliable, retryable steps within a single block
of code.  Each step retries on error - whether that's a network error, worker crash, or some other
failure.  Each step's data is recorded in "memory", and is available for use within the function.

## Why are durable workflow engines beneficial?

Writing code in this style has lots of benefits.  One important benefit is code is declarative and
colocated.  Instead of having many individually scattered jobs linking to each other, you write a
single function with straightforward logic.  This is simpler to write, maintain, and debug.

Depending on the workflow engine or platform that you use, lots of other nuances should also be
taken care of for you.  Things like retries, idempotency, observability, concurrency, and alerting
are all provided (with varying levels of ease or defaults).

It's also a force multiplier.  Any engineer can pick up this code and work on complex code without
worrying about race conditions.  Frontend engineers, backend engineers, and product engineers can
jump right in without learning specifics or implementation details.  This frees up time and makes
teams more effective.

## How workflow engines work

Every workflow engine provides primitives that developers use to assemble their core workflows.

Two primitives available in every platform are `steps` (single transactions that must complete once)
and `sleeps` (the ability to wait a specific amount of time and reusme functions). Both of these
require a queue under the hood.  Therefore, fundamentally **all workflow engines abstract some sort
of queue**.

Modern workflow engines typically all do something similar:

1. When a workflow is initialized (a `run`), a job is enqueued with the workflow's arguments (input event) recorded.
2. An execution engine reads jobs from the queue and invokes the workflow, passing in the workflow's current state as an argument to the SDK
3. The SDK reads the current state and invokes the underlying workflow code.  Any previously completed step is memoized so that it doesn't re-run.
4. Another step in the workflow runs.  The workflow run's state is updated atomically, and a new step is enqueued.

At a high level, it's a pretty simple loop.  Run the workflow, check for a new step, update state,
and re-run the function.  

While you could describe workflow engines as memoization engines, it's also fair to say that
workflow engines turn your functions into something like a [generator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator).
Each step runs once, and the function yields to new steps once.

This belies a lot of complexity under the hood to make workflows reliable. What if workflows never end?
What if backpressure grows, and workflows are started faster than they finish?  How does step
parallelism work?  These are not simple problems, and the solution changes depending on which
workflow engine you use.  Some engines push the complexity to you, the developer.  Some have no
answer to these problems, and stick with single-threaded no-concurrency execution.

## How Inngest works

Inngest is a durable workflow engine which allows you to also work with events.  If you're familiar
with `onClick` handlers on the web you're familiar with events.  An event is an object that contains
data which is created whenever something happens. A webhook is an event.  A user signup is an event.
And so on.

In Inngest, workflows are simple functions.  They run any time specific events are received.  You
can also sample events from a stream within a function, or add automatic function cancellation based
off of events:

```typescript
export default inngest.createFunction(
  {
    name: "User onboarding campaign"
    cancelOn: [
      // Automatically cancel this function any time the user is deleted.  This prevents
      // developers from having to pass or store workflow run IDs around, or handle state
      // checking within functions.
      {
        event: "app/user.deleted",
        if: "event.data.userId == async.data.userId",
      },
    ]
  },
  { event: "app/user.signup" },
  async ({ event, step }) => {
    // Wait for the `app/user.profile.completed` event to be received with the same user
    // ID for up to 24 hours.  Whenever the event is received, this function will be
    // resumed and `profileComplete` will hold the received event data.  If this times out
    // the variable will be `null`.
    const profileComplete = await step.waitForEvent(
      "app/user.profile.completed",
      {
        timeout: "24h",
        if: `async.data.userId == "${event.data.userId}"`,
      }
    );

    if (profileComplete === null) {
      // Send the user a followup.
    }
  }
);
```

This decouples code.  Instead of modifying code which handles user signups, we create a workflow
which automatically runs any time the signup event is received. To make this happen, a few extra
additions are necessary to a regular workflow engine.  The engine itself needs to be modified to
work with event streams.  It needs to combine queues with message brokers.  This is a non-trivial
change.

When an event is received by the workflow engine, a few things happen in parallel:

- New function runs are started if they're triggered by the event
- Function cancellations are evaluated and processed
- `waitForEvent` signals are evaluated and processed

Once processed, these invoke the queueing engine to resume functions using a queue.

Inngest's queue is unique.  Inngest's queueing system creates two queues for every function deployed.
Workers are shared-nothing, and pick up work from each queue without communication and minimal contention,
whilst still having guarantees that the oldest jobs are worked on first.  It prioritizes finishing
functions in order (excepting retries), and allows simple management of backpressure and load-shedding.

This allows us to scale functions seamlessly across a fleet of executors, without worrying about
conflicting state or coordination.  We'll dive into event matching and queueing systems in future
blog posts.

I hope this gives an overview to workflow engines, how they're used, and the basic execution loops
that power them.  Workflow engines are modern replacements for queues, offering tooling and semantics
above and beyond what raw infrastructure provides.
