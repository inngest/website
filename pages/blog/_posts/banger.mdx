---
heading: A Deep Dive into a Video Rendering Pipeline
showSubtitle: true
subtitle: banger.show is a video app maker that heavily relies on background data processing
image: /assets/blog/banger/banger-main.jpg
date: 2024-05-01
author: Igor Samokhovets
disableCTA: true
---

import { YouTubeEmbed } from "@next/third-parties/google";

Hi everyone! My name is [Igor Samokhovets](https://twitter.com/IgorSamokhovets) and I'm a music producer who goes by the artist name Tequila Funk. Together with Mark Beziaev we created [banger.show](https://banger.show/) -- a video maker app for musicians, DJs, and labels. It allows music industry people to create stunning visual assets for their music.

<YouTubeEmbed videoid="eSLKm6IfZM4" height={300} params="controls=0"/>

 Creating a video for your new song takes only a few minutes and you don't need to know any complex software because banger.show works in your browser.


## Making background processing snappy

At banger.show, we do a lot of background processing. Managing render states, generating visual assets in the background, and even handling the rendering process on remote distributed workers. We chose Inngest because there's no better way to handle background jobs if you're using Next.js.

Let's dive into some parts of the video rendering pipeline.

### 1. Updating the render status

The first step in the render pipeline is to update the render status and set user credits on hold

```js
const updatedVideo = await step.run('Update user balance', async () => {
  await dbConnect()

  const render = await VideoModel.findOneAndUpdate(
    { _id: videoId },
    { $set: { renderProgress: 0, renderTime: 0, status: 'pending' } },
    { new: true }
  )
    .populate('user')
    .lean()

  invariant(video, 'no render found')

  // Simplified
  await UserModel.updateOne(
    {
      _id: video.user._id
    },
    {
      $inc: { unitsRemaining: -video.videoDuration }
    }
  )

  return video
})
```

### 2. Cropping the audio file

In banger.show, user should select a fragment of the song to create a videoization for it. In the background job, we:

- Crop audio file based on the user selection.
- Convert the file to MP3 format for disk space efficiency and optimal compatibility.

Let's see it in code.

```js
const croppedMp3Url = await step.run(
  'Trim audio and convert to mp3',
  async () => {
    // create temporary file
    const tempFilePath = `${os.tmpdir()}/${videoId}.mp3`

    await execa(`ffmpeg`, [
      '-i',
      updatedVideo.audioFileURL, // ffmpeg will grab input from URL
      '-map',
      '0:a',
      '-map_metadata',
      '-1',
      '-ab',
      '320k',
      '-f',
      'aac',
      '-ss',
      String(updatedVideo.regionStartTime), // start time
      '-to',
      String(updatedVideo.regionEndTime), // end time
      tempFilePath
    ])

    const croppedAudioS3Key = await getAudioFileKey(videoId)

    // upload mp3 to file storage
    const mp3URL = await uploadFile({
      Key: croppedAudioS3Key,
      Body: fs.createReadStream(tempFilePath)
    })

    // remove temp file
    await unlink(tempFilePath)

    await dbConnect()

    await VideoModel.updateOne(
      { _id: videoId },
      { $set: { croppedAudioFileURL: mp3URL } }
    )

    return mp3URL
  }
)
```

### 3. Rendering the video

The next step is to render the video using remote workers with beefy CPUs and GPUs.

![A screenshot of the Banger app](/assets/blog/banger/banger-app.png)

We have a sub-queue that communicates with our own infrastructure. We send a job to the queue while Inngest allows us to wait until the job is done and handles new progress events.

```js
const { videoFileURL, renderTime } = await step.run(
  'Render video to s3',
  async () => {
    const outKey = await getVideoOutKey(videoId)

    const userBundle = bundles.find((p) => p.key === updatedVideo.user.bundle)

    if (!userBundle) {
      throw new NonRetriableError('no bundle assigned to user')
    }

    await dbConnect()

    const video = await VideoModel.findOne({
      _id: videoId
    }).populate('user')

    if (!video) {
      throw new NonRetriableError('no video found')
    }

    // attempt is provided by Inngest.
    // if video fails to render from the first attempt, we will pick different worker
    const renderer = await determineRenderer(video, attempt)

    // CRF of the video based on user bundle
    const constantRateFactor = determineRemotionConstantRateFactor(
      video.user.bundle
    )

    const renderPriority = await determineQueuePriority(video.user.bundle)

    logger.info(
      `Rendering Remotion video with renderer ${renderer} and crf ${constantRateFactor}`
    )

    let processingStatusIsSet = false

    const renderedVideo = await renderVideo({
      videoId: videoId,
      priority: renderPriority,
      renderOptions: {
        crf: constantRateFactor,
        concurrency: determineRemotionConcurrency(video),
        ...(video.hdr && {
          colorSpace: 'bt2020-ncl'
        })
      },
      inputPropsOverride: {
        ...video.videoSettings,
        videoFormat: video.videoFormat
      },
      renderer,
      audioURL: croppedMp3Url,
      startTime: 0,
      endTime: video.videoDuration,
      outKey,
      onProgress: async (progress) => {
        await VideoModel.updateOne(
          {
            _id: videoId
          },
          { $set: { renderProgress: progress, status: 'processing' } }
        )
      }
    })

    return renderedVideo
  }
)
```

### 4. Invalidate CDN cache

There are some cases when video needs to be re-rendered. To make sure CDN cache is always fresh, we purge it each time the video renders.

```js
await step.run('Create invalidation on CloudFront', async () => {
  try {
    const { pathname: videoPathnameToInvalidate } = new URL(videoFileURL)

    return await invalidateCloudFrontPaths([
      videoPathnameToInvalidate,
      `/thumbnails/${videoId}.jpg`,
      `/thumbnails/${videoId}-square.jpg`
    ])
  } catch (error) {
    sendTelegramLog(`Invalidation failed for ${videoId}: ${error.message}`)
    return `Invalidation failed, skipping: ${error.message}`
  }
})
```

### 5. Updating video status to "ready"

After video is successfully rendered and we have obtained a URL, we set video status to "ready" and update `renderTime`.

```js
await step.run('Update video status to ready', () =>
  Promise.all([
    VideoModel.updateOne(
      { _id: videoId },
      {
        $set: {
          status: 'ready',
          videoFileURL
        },
        $inc: {
          renderTime
        }
      }
    )
  ])
)
```

### 6. Creating a video thumbnail

Finally, we also want to create a thumbnail for each video to show it in listings or use as a video posters.

```js
await step.run('Generate thumbnail and upload to S3', async () => {
  const thumbnailFilePath = `${os.tmpdir()}/${videoId}-thumbnail.jpg`

  await execa(`ffmpeg`, [
    '-i',
    videoFileURL, // ffmpeg will grab input from URL
    '-vf',
    'thumbnail=300',
    '-frames:v', // only one frame
    '1',
    thumbnailFilePath
  ])

  const thumbnailFileURL = await uploadFile({
    Key: `thumbnails/${videoId}.jpg`,
    Body: fs.createReadStream(thumbnailFilePath)
  })

  await dbConnect()
  await VideoModel.updateOne(
    { _id: videoId },
    { $set: { thumbnailURL: thumbnailFileURL } }
  )

  await unlink(thumbnailFilePath)
})
```

## Working with Inngest

Inngest makes the difficult parts easy.

For example, there's no simpler way to put it: I find the `steps` concept mindblowing. I wished something like this was available back in 2019, when I was just starting out with BullMQ, Agenda.js, and other solutions. It's a really sweet abstraction. I also enjoy observability, so I can track each step and function run in one dashboard.

_You can reach out to Igor on [Twitter](https://twitter.com/IgorSamokhovets) or listen to his music on [Spotify](https://open.spotify.com/artist/66PsDRGGiij2rHAK21GUEB)._