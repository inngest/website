import { ResourceGrid, Resource, ExampleGrid } from 'src/shared/Docs/Resources';
import { Example } from 'src/shared/Docs/Examples';

import { BookOpenIcon, VideoCameraIcon, MicrophoneIcon } from "@heroicons/react/24/outline";

export const description = "Learn how to use Inngest for AI automated workflows, AI agents, and RAG."

# AI Agents and RAG

Inngest offers tools to support the development of AI-powered applications. Whether you're building AI agents, automating tasks, or orchestrating and managing AI workflows, Inngest provides features that accommodate various needs and requirements, such as concurrency, debouncing, or throttling (see ["Related Concepts"](#related-concepts)).

## Quick Snippet

Below is an example of a RAG workflow (from the ["AI in production"](/blog/ai-in-production-managing-capacity-with-flow-control) blog post), which uses [Inngest steps](/docs/learn/inngest-steps) to guarantee automatic retries on failure.

```typescript {{ title: "./inngest/functions.ts" }}
export const userWorkflow = inngest.createFunction(
  fnOptions,
  fnListener,
  async ({ event, step }) => {
    const similar = await step.run("query-vectordb", async () => {
      // Query a vectorDB for similar results given input
      const embedding = createEmbedding(event.data.input)
      return await index.query({ vector: embedding, topK: 3 }).matches
    })

    const response = await step.run("generate-llm-response", async () => {
      // Inject our prompt given similar search results and event.data.input
      const prompt = createAgentPrompt(similar, event.data.input)
      return await llm.createCompletion({
        model: "gpt-3.5-turbo",
        prompt,
      })
    })

    const entities = await step.run("extract-entities-hf", async () => {
      // Extract entities from the generated response using Hugging Face's named entity recognition model
      let pipe = await pipeline(
        "entity-extraction",
        "Xenova/bert-base-multilingual-uncased-sentiment"
      )
      return await pipe(response)
    })

    const summary = await step.run("generate-summary-anthropic", async () => {
      // Generate a summary document using the extracted entities and the Anthropic API
      const anthropic = new Anthropic()

      const anthropicPrompt = `The following entities were mentioned in the response: ${entities.join(
        ", "
      )}. Please generate a summary document based on these entities and the original response:\n\nResponse: ${response}`

      return await anthropic.messages.create({
        model: "claude-3-opus-20240229",
        max_tokens: 1024,
        messages: [{ role: "user", content: anthropicPrompt }],
      })
    })

    await step.run("save-to-db", async () => {
      // Save the generated response, extracted entities, and summary to the database
      await db.summaries.create({
        requestID: event.data.requestID,
        response,
        entities,
        summary,
      })
    })
  }
)
```

## App examples
Here are apps that use Inngest to power AI workflows:

<ResourceGrid cols={2}>

<Example example={{
title: "Integrate AI agents with Inngest",
technology: "Next.js, OpenAI",
description: "AI-powered task automation in Next.js using OpenAI and Inngest. Enhance productivity with automated workflows.",
pattern: 1,
demo: "https://www.loom.com/share/c43aa34205854096bcec0a96e7ba5634?sid=839b1adc-ad39-4540-9995-88967f2b6da9",
github: "https://github.com/joelhooks/inngest-partykit-nextjs-openai",
image: "/assets/docs/examples/ai-agents/vercel-openai-inngest-partykit-demo.png",
author: "Joel Hooks",
authorSocial: "https://twitter.com/jhooks"
}}/>

<Example example={{
title: "PCXI starter",
technology: "Next.js, OpenAI, Xata, Prisma, Clerk",
description: "A boilerplate project for the PCXI stack featuring an OpenAI call",
pattern: 1,
github: "https://github.com/inngest/next-pxci-starter",
image: "/assets/docs/examples/ai-agents/pcxi-starter.png",
}}/>

</ResourceGrid>

## Resources
Check the resources below to learn more about working with AI using Inngest:

<ResourceGrid cols={2}>

<Resource resource={{
href: "/blog/ai-in-production-managing-capacity-with-flow-control",
name: 'Blog: "AI in production: Managing capacity with flow control"',
icon: BookOpenIcon,
description: "Learn how to manage AI capacity in production using Inngest's flow control techniques, including throttling, concurrency, debouncing, and prioritization, to optimize performance and cost-efficiency.",
pattern: 1,
}}/>

<Resource resource={{
href: "https://a16z.com/podcast/building-production-workflows-for-ai-applications/",
name: 'Podcast: "Building Production Workflows for AI Applications"',
icon: MicrophoneIcon,
description: "Tony Holdstock-Brown and Yoko Li discuss the reality and complexity of running AI agents and other multistep AI workflows in production.",
pattern: 1,
}}/>

<Resource resource={{
href: "https://www.youtube.com/watch?v=EoFI_Bmzb4g",
name: 'Talk: "Automate All of Your Customer Interactions with AI in Next.js"',
icon: VideoCameraIcon,
description: "Joel Hooks discusses managing long-running processes like generative AI to automate customer interactions effectively.",
pattern: 1,
}}/>


<Resource resource={{
href: "/blog/semi-autonomous-ai-agents",
name: 'Blog: "Semi-Autonomous AI Agents and Collaborative Multiplayer Asynchronous Workflows"',
icon: BookOpenIcon,
description: "Build an AI agent that reads from Linear issues, returns relevant issues based on queries, and allows actions on those issues.",
pattern: 1,
}}/>

<Resource resource={{
href: "https://www.youtube.com/watch?v=PCq6DozV-mY",
name: 'Video: "Chaining Prompts The Easy Way - Using Inngest Serverless Jobs with OpenAI"',
icon: VideoCameraIcon,
description: "Doug Silkstone demonstrates how to chain together prompts and get content in next to no time at all.",
pattern: 1,
}}/>

</ResourceGrid>

## Related concepts

- [Concurrency](/docs/guides/concurrency): control the number of steps executing code at any one time.
- [Debouncing](/docs/guides/debounce): delay function execution until a series of events are no longer received.
- [Prioritization](/docs/guides/priority): dynamically execute some runs ahead or behind others based on any data.
- [Rate limiting](/docs/guides/rate-limiting): limit on how many function runs can start within a time period.
- [Steps](/docs/reference/functions/step-run): individual tasks within a function that can be executed independently with a guaranteed retrial.
- [Throttling](/docs/guides/throttling): specify how many function runs can start within a time period.